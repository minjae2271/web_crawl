{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "with open('/Users/minjae/Desktop/2.html') as fp:\n",
    "    soup = bs(fp, 'html.parser')\n",
    "    \n",
    "    print(soup)\n",
    "    #print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag parse 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#태그검색\n",
    "find() : 조건에 맞는 태그를 하나 가져옴\n",
    "find_all() : 조건에 맞는 태그를 모두 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_find = soup.find('div')\n",
    "print(soup_find)\n",
    "\n",
    "# 위의 파싱과 동일한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_find_all = soup.find_all('div')\n",
    "print(soup_find_all)\n",
    "\n",
    "#리스트 형태로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_by_class = soup.find_all('div',{'class':'logos'})\n",
    "print(find_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_by_id = soup.find_all('a',{'id':'python'})\n",
    "print(find_by_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find('a').string\n",
    "\n",
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_url = soup.find_all('a')\n",
    "#print(site_url)\n",
    "\n",
    "for url in site_url:\n",
    "    print(url.get('href'))\n",
    "    #print(url.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#urllib : 웹사이트에서 쉽게 정보를 가져올 수 있게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "res = request.urlopen(\"https://www.naver.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.code\n",
    "\n",
    "#200 : ㅇㅋ \n",
    "#404 : ㄴㄴ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = res.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이수안 컴퓨터 연구소 : 네이버 뮤직 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://music.naver.com/listen/top100.nhn?domain=DOMESTIC_V2&page=1'\n",
    "\n",
    "html = request.urlopen(url).read()\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# print(soup)\n",
    "\n",
    "#<a href=\"#42644553\" class=\"_title title NPI=a:track,r:2,i:42644553\" title=\"Lovesick Girls\"><span class=\"ellipsis\">Lovesick Girls</span></a>\n",
    "titles = soup.find_all('a',{'class':'_title'})\n",
    "\n",
    "for title in titles:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#parser : UTF-8로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = request.urlopen(\"https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%ED%94%BC%EC%B9%B4%EC%B8%84\")\n",
    "search.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = request.urlopen(\"https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=꼬부기\")\n",
    "search.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=\"\n",
    "plusUrl = \"꼬부기\"\n",
    "\n",
    "url = baseUrl + plusUrl\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plusUrl = parse.quote_plus(plusUrl)\n",
    "\n",
    "url = baseUrl + plusUrl\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#프로그래머 김플 스튜디오 강좌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import NavigableString, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://search.shopping.naver.com/search/all?where=all&frm=NVSCTAB&query='\n",
    "plusUrl = input('검색어를 입력하세요:')\n",
    "url = baseUrl + urllib.parse.quote_plus(plusUrl)\n",
    "\n",
    "\n",
    "html = urllib.request.urlopen(url).read()\n",
    "\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "#__next > div > div.container > div.style_inner__18zZX > div.style_content_wrap__1PzEo > div.style_content__2T20F > ul > div > div:nth-child(1) > li > div > div.basicList_info_area__17Xyo > div.basicList_title__3P9Q7\n",
    "title = soup.find_all(class_='basicList_link__1MaTN')\n",
    "print(len(title))\n",
    "#print(title)\n",
    "\n",
    "for ele in title:\n",
    "    print(ele.get('title'))\n",
    "    print(ele.get('href'))\n",
    "    print()\n",
    "\n",
    "# for ele in title:\n",
    "#     if isinstance(ele, NavigableString):\n",
    "#         continue\n",
    "#     if isinstance(ele, Tag):\n",
    "#         print(ele.attrs['title'])\n",
    "#         print(ele.attrs['href'])\n",
    "#         print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Naver 이미지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://search.naver.com/search.naver?where=image&sm=tab_jum&query=%EC%82%AC%EA%B3%BC\n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "plusUrl = input('검색어를 입력하세요')\n",
    "url = baseUrl + urllib.parse.quote_plus(plusUrl)\n",
    "\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "img = soup.find_all(class_='_img')\n",
    "\n",
    "n = 1\n",
    "for img_ele in img:\n",
    "    imgUrl = img_ele.get('data-source')\n",
    "    print(imgUrl)\n",
    "    with urllib.request.urlopen(imgUrl) as f:\n",
    "        #바이너리기 때문에 wb\n",
    "        with open('./naver_img/' + plusUrl + str(n) + '.jpg', 'wb') as h:\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n+=1\n",
    "        \n",
    "print('다운로드 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#인스타그램 이미지 크롤링\n",
    "\n",
    "사전준비 : chromedriver (https://chromedriver.chromium.org/downloads 상위 버전 다운로드) -> 파이썬파일과 동일 경로에 다운받은 파일 이동\n",
    "\n",
    "구글검색창에 instagram 파이썬으로 검색하면 로그인 하지않고 게시물 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.instagram.com/explore/tags/%EC%9D%84%EC%A7%80%EB%A1%9C%EB%A7%9B%EC%A7%91/\n",
    "baseUrl = 'https://www.instagram.com/explore/tags/'\n",
    "plusUrl = input('인스타 검색어를 입력하세요.')\n",
    "url = baseUrl + quote_plus(plusUrl)\n",
    "\n",
    "#인스타그램의 웹구조 -> JS기 때문에 selenium 사용\n",
    "#.Chrome() -> 에러발생하여 절대경로 추가 (driver파일을 usr/bin으로 옮겨도 해결된다고 함)\n",
    "driver = webdriver.Chrome('/Users/minjae/web_crawl/chromedriver')\n",
    "driver.get(url)\n",
    "\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "for i in range(5):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(.5)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "# v1Nh3 kIKUG  _bz0w class가 3개 -> .으로 구분\n",
    "insta = soup.select('.v1Nh3.kIKUG._bz0w')\n",
    "\n",
    "#출력 확인하는 습관!\n",
    "print(insta[0])\n",
    "\n",
    "# n = 1\n",
    "# for i in insta:\n",
    "#     print(\"https://www.instagram.com/\" + i.a['href'])\n",
    "#     imgUrl = i.select_one('.KL4Bh').img['src']\n",
    "#     with urlopen(imgUrl) as f:\n",
    "#         with open('./insta_img/' + plusUrl + str(n) + 'jpg', 'wb') as h:\n",
    "#             img = f.read()\n",
    "#             h.write(img)\n",
    "#     n+=1\n",
    "\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#네이버 블로그 크롤링 (여러페이지) -> page 처리가 관건!\n",
    "#1번 소스 코드를 수정하여 만들어보자\n",
    "#1번 import cell 실행 해주세요\n",
    "\n",
    "<a href=\"?date_from=&amp;date_option=0&amp;date_to=&amp;dup_remove=1&amp;nso=&amp;post_blogurl=&amp;post_blogurl_without=&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sm=tab_pge&amp;srchby=all&amp;st=sim&amp;where=post&amp;start=51\" onclick=\"return goOtherCR(this,'a=blg.paging&amp;i=&amp;r=6&amp;u='+urlencode(urlexpand(this.href)));\">6</a>\n",
    "\n",
    "<a href=\"?date_from=&amp;date_option=0&amp;date_to=&amp;dup_remove=1&amp;nso=&amp;post_blogurl=&amp;post_blogurl_without=&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sm=tab_pge&amp;srchby=all&amp;st=sim&amp;where=post&amp;start=61\" onclick=\"return goOtherCR(this,'a=blg.paging&amp;i=&amp;r=7&amp;u='+urlencode(urlexpand(this.href)));\">7</a>\n",
    "\n",
    "<a href=\"?date_from=&amp;date_option=0&amp;date_to=&amp;dup_remove=1&amp;nso=&amp;post_blogurl=&amp;post_blogurl_without=&amp;query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&amp;sm=tab_pge&amp;srchby=all&amp;st=sim&amp;where=post&amp;start=71\" onclick=\"return goOtherCR(this,'a=blg.paging&amp;i=&amp;r=8&amp;u='+urlencode(urlexpand(this.href)));\">8</a>\n",
    "\n",
    "-> 6페이지의 start=51 / 7페이지의 start=61 / 8페이지의 start=71\n",
    "\n",
    "\n",
    "<a class=\"sh_blog_title _sp_each_url _sp_each_title\" href=\"https://blog.naver.com/0813dcba?Redirect=Log&amp;logNo=221950381025\" target=\"_blank\" onclick=\"return goOtherCR(this, 'a=blg*i.tit&amp;r=1&amp;i=90000003_0000000000000033AD460BE1&amp;u='+urlencode(this.href))\" title=\"푸드엔샵 에콜로 착즙주스 사과즙 대신 챙겨요\">푸드엔샵 에콜로 착즙주스 <strong class=\"hl\">사과</strong>즙 대신 챙겨요</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plusUrl = urllib.parse.quote_plus(input('검색어를 입력하세요:'))\n",
    "\n",
    "pageNum = 1\n",
    "\n",
    "i = input(\"몇페이지까지 크롤링을 할까요?\")\n",
    "\n",
    "lastPage = int(i) * 10 -9\n",
    "count = 1\n",
    "while pageNum<lastPage+1:\n",
    "    url = f'https://search.naver.com/search.naver?date_from=&date_option=10&date_to=&dup_remove=1&nso=&post_blogurl=&post_blogurl_without=&query={plusUrl}&sm=tab_pge&srchby=all&st=sim&where=post&start={pageNum}'\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = bs(html, 'html.parser')\n",
    "    \n",
    "    title = soup.find_all(class_='sh_blog_title')\n",
    "    \n",
    "    print(f'--------------{count}페이지 결과입니다')\n",
    "    for ele in title:\n",
    "        print(ele.attrs['title'])\n",
    "        print(ele.attrs['href'])\n",
    "    print()\n",
    "    \n",
    "    count+=1\n",
    "    pageNum += 10\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
